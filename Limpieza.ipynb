{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Imports\n",
    "import pandas as pd\n",
    "import re\n",
    "from unidecode import unidecode  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inciso 1\n",
    "#### Descargue los datos\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "alta_verapaz_diversificado = pd.read_csv('Diversificado/alta_verapaz_diversificado.csv',encoding='utf-8',sep=';')\n",
    "baja_verapaz_diversificado = pd.read_csv('Diversificado/baja_verapaz_diversificado.csv',encoding='utf-8',sep=';')\n",
    "capital_diversificado = pd.read_csv('Diversificado/capital_diversificado.csv',encoding='utf-8',sep=';')\n",
    "chimaltenango_diversificado = pd.read_csv('Diversificado/chimaltenango_diversificado.csv',encoding='utf-8',sep=';')\n",
    "chiquimula_diversificado = pd.read_csv('Diversificado/chiquimula_diversificado.csv',encoding='utf-8',sep=';')\n",
    "escuintla_diversificado = pd.read_csv('Diversificado/escuintla_diversificado.csv',encoding='utf-8',sep=';')\n",
    "guatemala_diversificado = pd.read_csv('Diversificado/guatemala_diversificado.csv',encoding='utf-8',sep=';')\n",
    "huehuetenango_diversificado = pd.read_csv('Diversificado/huehuetenango_diversificado.csv',encoding='utf-8',sep=';')\n",
    "izabal_diversificado = pd.read_csv('Diversificado/izabal_diversificado.csv',encoding='utf-8',sep=';')\n",
    "jalapa_diversificado = pd.read_csv('Diversificado/jalapa_diversificado.csv',encoding='utf-8',sep=';')\n",
    "jutiapa_diversificado = pd.read_csv('Diversificado/jutiapa_diversificado.csv',encoding='utf-8',sep=';')\n",
    "peten_diversificado = pd.read_csv('Diversificado/peten_diversificado.csv',encoding='utf-8',sep=';')\n",
    "progreso_diversificado = pd.read_csv('Diversificado/progreso_diversificado.csv',encoding='utf-8',sep=';')\n",
    "quetzaltenango_diversificado = pd.read_csv('Diversificado/quetzaltenango_diversificado.csv',encoding='utf-8',sep=';')\n",
    "quiche_diversificado = pd.read_csv('Diversificado/quiche_diversificado.csv',encoding='utf-8',sep=';')\n",
    "retalhuleu_diversificado = pd.read_csv('Diversificado/retalhuleu_diversificado.csv',encoding='utf-8',sep=';')\n",
    "sacatepequez_diversificado = pd.read_csv('Diversificado/sacatepequez_diversificado.csv',encoding='utf-8',sep=';')\n",
    "san_marcos_diversificado = pd.read_csv('Diversificado/san_marcos_diversificado.csv',encoding='utf-8',sep=';')\n",
    "santa_rosa_diversificado = pd.read_csv('Diversificado/santa_rosa_diversificado.csv',encoding='utf-8',sep=';')\n",
    "solola_diversificado = pd.read_csv('Diversificado/solola_diversificado.csv',encoding='utf-8',sep=';')\n",
    "suchitepequez_diversificado = pd.read_csv('Diversificado/suchitepequez_diversificado.csv',encoding='utf-8',sep=';')\n",
    "totonicapan_diversificado = pd.read_csv('Diversificado/totonicapan_diversificado.csv',encoding='utf-8',sep=';')\n",
    "zacapa_diversificado = pd.read_csv('Diversificado/zacapa_diversificado.csv',encoding='utf-8', sep=';')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dfs = [\n",
    "    alta_verapaz_diversificado,\n",
    "    baja_verapaz_diversificado,\n",
    "    capital_diversificado,\n",
    "    chimaltenango_diversificado,\n",
    "    chiquimula_diversificado,\n",
    "    progreso_diversificado,\n",
    "    escuintla_diversificado,\n",
    "    guatemala_diversificado,\n",
    "    huehuetenango_diversificado,\n",
    "    izabal_diversificado,\n",
    "    jalapa_diversificado,\n",
    "    jutiapa_diversificado,\n",
    "    peten_diversificado,\n",
    "    quetzaltenango_diversificado,\n",
    "    quiche_diversificado,\n",
    "    retalhuleu_diversificado,\n",
    "    sacatepequez_diversificado,\n",
    "    san_marcos_diversificado,\n",
    "    santa_rosa_diversificado,\n",
    "    solola_diversificado,\n",
    "    suchitepequez_diversificado,\n",
    "    totonicapan_diversificado,\n",
    "    zacapa_diversificado,\n",
    "]\n",
    "\n",
    "dfs_names =[\n",
    "    \"alta_verapaz_diversificado\",\n",
    "    \"baja_verapaz_diversificado\",\n",
    "    \"capital_diversificado\",\n",
    "    \"chimaltenango_diversificado\",\n",
    "    \"chiquimula_diversificado\",\n",
    "    \"progreso_diversificado\",\n",
    "    \"escuintla_diversificado\",\n",
    "    \"guatemala_diversificado\",\n",
    "    \"huehuetenango_diversificado\",\n",
    "    \"izabal_diversificado\",\n",
    "    \"jalapa_diversificado\",\n",
    "    \"jutiapa_diversificado\",\n",
    "    \"peten_diversificado\",\n",
    "    \"quetzaltenango_diversificado\",\n",
    "    \"quiche_diversificado\",\n",
    "    \"retalhuleu_diversificado\",\n",
    "    \"sacatepequez_diversificado\",\n",
    "    \"san_marcos_diversificado\",\n",
    "    \"santa_rosa_diversificado\",\n",
    "    \"solola_diversificado\",\n",
    "    \"suchitepequez_diversificado\",\n",
    "    \"totonicapan_diversificado\",\n",
    "    \"zacapa_diversificado\",\n",
    "    \n",
    "]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inciso 2\n",
    "#### Describa el dataset y las operaciones de limpieza que realizara"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Mostrar los tipos de datos de las columnas de cada dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for df in dfs:\n",
    "    print(df.dtypes)\n",
    "    print('------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Descripcion de las variables\n",
    "\n",
    "Como se observa arriba, no se pueden observar los tipos de las variables. Por lo mismo se indicará esto a continuación:\n",
    "* CODIGO: cualitativa nominal (string)\n",
    "* DISTRITO: cualitativa nominal (string)\n",
    "* DEPARTAMENTO: cualitativa nominal (string)\n",
    "* MUNICIPIO: cualitativa nominal (string)\n",
    "* ESTABLECIMIENTO: cualitativa nominal (string)\n",
    "* DIRECCION: cualitativa nominal (string)\n",
    "* TELEFONO: cualitativa nominal (string)\n",
    "* SUPERVISOR: cualitativa nominal (string)\n",
    "* DIRECTOR: cualitativa nominal (string)\n",
    "* NIVEL: cualitativa ordinal (string)\n",
    "* SECTOR: cualitativa nominal (string)\n",
    "* AREA: cualitativa nominal (string)\n",
    "* STATUS: cualitativa nominal (string)\n",
    "* MODALIDAD: cualitativa nominal (string)\n",
    "* JORNADA: cualitativa nominal (string)\n",
    "* PLAN: cualitativa nominal (string)\n",
    "* DEPARTAMENTAL: cualitativa nominal (string)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Acciones a realizar:\n",
    "\n",
    "* Establecer tipo a cada columna del dataset\n",
    "\n",
    "* Analisis de NA's\n",
    "\n",
    "* Analisis de duplicados\n",
    "\n",
    "* Eliminación de caracteres especiales como son las tildes\n",
    "\n",
    "* Validar que todos los datasets tengan las mismas columnas y si no arreglarlo\n",
    "\n",
    "* Eliminar columnas que no aportan valor\n",
    "\n",
    "* Realizar hot encoding de las columnas categoricas\n",
    "\n",
    "\n",
    "Al finalizar la limpieza de datos se uniran todos los datasets en uno solo para poder realizar el analisis de datos.\n",
    "       "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inciso 3\n",
    "#### Realice los procesos de limpieza de datos que considere necesarios para que el dataset sea apto para el análisis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_variable_names():\n",
    "    union = set()\n",
    "    common = set()\n",
    "    i = 0\n",
    "    for df in dfs:\n",
    "        union = union.union(set(df.columns))\n",
    "        common = union.intersection(set(df.columns))\n",
    "    \n",
    "    if union == common:\n",
    "        print(\"All dataframes have the same variables\")\n",
    "    else:\n",
    "        print(\"Not all dataframes have the same variables\")\n",
    "\n",
    "check_variable_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Definir una función para contar las tildes en un texto\n",
    "def contar_tildes(texto):\n",
    "    \n",
    "    return len(re.findall(r'[áéíóúÁÉÍÓÚ]', texto))\n",
    "\n",
    "# Aplicar la función a cada elemento del DataFrame\n",
    "\n",
    "for df in range(len(dfs)):\n",
    "    texto_df = dfs[df].to_string(index=False)\n",
    "    conteo_tildes_por_columna = contar_tildes(texto_df)\n",
    "    print(\"El data frame de \",dfs_names[df],\"tiene: \",conteo_tildes_por_columna,\" tildes\")\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Definir una función para eliminar las tildes de un texto\n",
    "def quitar_tildes(texto):\n",
    "    return unidecode(texto)\n",
    "\n",
    "for df in range(len(dfs)):\n",
    "    dfs[df] = dfs[df].applymap(quitar_tildes)\n",
    "    texto_df = dfs[df].to_string(index=False)\n",
    "    conteo_tildes_por_columna = contar_tildes(texto_df)\n",
    "    print(\"El data frame de \",dfs_names[df],\"tiene: \",conteo_tildes_por_columna,\" tildes\")\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
